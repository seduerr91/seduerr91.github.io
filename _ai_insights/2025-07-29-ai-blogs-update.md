---
title: AI Daily
tags: [AI, Blogs]
style: fill
color: secondary
description: Daily update on AI blogs of 07-29
---

Meta has announced ExecuTorch, a PyTorch-based inference framework designed specifically for edge devices, with support from major partners like Arm, Apple, and Qualcomm. The framework powers new on-device AI features across Meta’s apps—including Instagram, WhatsApp, Messenger, and Facebook—enabling improved latency, privacy, offline capabilities, and overall model efficiency. Notable applications include Instagram’s Cutouts, video quality optimization in WhatsApp, and end-to-end encryption in Messenger. ExecuTorch optimizes model deployment for real-world use and invites community collaboration, signaling a significant industry move toward advanced, privacy-preserving on-device AI.

### [Accelerating on-device ML on Meta’s family of apps with ExecuTorch](https://engineering.fb.com/2025/07/28/android/executorch-on-device-ml-meta-family-of-apps/)
**Source:** Meta AI

ExecuTorch, a PyTorch inference framework for edge devices by Meta with support from Arm, Apple, and Qualcomm, enhances on-device ML for Meta's apps, improving latency, user privacy, and offline functionalities. The post highlights the on-device AI features powered by ExecuTorch in Instagram, WhatsApp, Messenger, and Facebook, resulting in improved model performance and efficiency. ExecuTorch, built with PyTorch 2.x, converts models for efficient deployment, enhancing user experiences globally. Key implementations include Instagram's Cutouts feature, bandwidth estimation models in WhatsApp for video quality optimization, and enabling end-to-end encryption on Messenger. ExecuTorch's rollout has shown performance enhancements across various models, contributing to the future of on-device AI. The post encourages community contributions to the ExecuTorch project.